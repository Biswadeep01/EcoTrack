# -*- coding: utf-8 -*-
"""prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SUR4-L6w1GAd3chI-_IqtbszzQzp4HIT
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.optimizers import Adam
import joblib

# Step 1: Read the CSV file
df = pd.read_csv('output.csv')

df['date'] = pd.to_datetime(df['date'], dayfirst=True).map(pd.Timestamp.toordinal)
# Normalize the total carbon emission amounts
scaler = MinMaxScaler(feature_range=(0, 1))
df['total_carbon_emission'] = scaler.fit_transform(df[['total_carbon_emission']])

# Step 3: Split the data
X = df['date'].values.reshape(-1, 1)
y = df['total_carbon_emission'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Create the model
model = Sequential([
    Dense(64, activation='relu', input_shape=(1,)),
    Dense(64, activation='relu'),
    Dense(1)
])

# Step 5: Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# Step 6: Train the model
model.fit(X_train, y_train, epochs=110, batch_size=32, validation_split=0.2)

# Step 7: Evaluate the model
model.evaluate(X_test, y_test)

joblib.dump(model, 'carbon_emission_model.pkl')

import pandas as pd
import numpy as np
import joblib
from datetime import datetime, timedelta

# Load the model and the pre-fitted scaler
model = joblib.load('carbon_emission_model.pkl')
#scaler = joblib.load('scaler.pkl')  # Load the pre-fitted scaler

# Get user input
month_year_str = input("Enter month and year (YYYY-MM): ")
year, month = map(int, month_year_str.split('-'))

# Generate all Wednesdays of the specified month
first_day = datetime(year, month, 1)
wednesdays = [first_day + timedelta(days=(2 - first_day.weekday() + 7 * i)) for i in range(5) if (first_day + timedelta(days=(2 - first_day.weekday() + 7 * i))).month == month]

# Prepare the data for prediction
wednesday_ordinals = np.array([datetime.toordinal(wed) for wed in wednesdays]).reshape(-1, 1)
predicted_emissions = model.predict(wednesday_ordinals)
predicted_emissions = scaler.inverse_transform(predicted_emissions)

# Create a DataFrame to store the results
results = pd.DataFrame({
    'Date': [wed.strftime("%Y-%m-%d") for wed in wednesdays],
    'Predicted Carbon Emission': predicted_emissions.flatten()
})

# Save the results to a CSV file
csv_filename = f"predicted_emissions_{year}_{month:02d}.csv"
results.to_csv(csv_filename, index=False)

print(f"Predicted carbon emissions saved to {csv_filename}")

df1 = pd.read_csv('predicted_emissions_2027_06.csv')
df1.head()