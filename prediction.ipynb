{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKaMXvKBeW8W",
        "outputId": "16b2714c-eb8a-4f94-bf87-eb365828b7ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n",
            "5/5 [==============================] - 1s 51ms/step - loss: 9233842176.0000 - val_loss: 3245078784.0000\n",
            "Epoch 2/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1558084480.0000 - val_loss: 45847624.0000\n",
            "Epoch 3/110\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 141589344.0000 - val_loss: 608663232.0000\n",
            "Epoch 4/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 823927360.0000 - val_loss: 903899840.0000\n",
            "Epoch 5/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 715286656.0000 - val_loss: 353978176.0000\n",
            "Epoch 6/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 182069280.0000 - val_loss: 9851154.0000\n",
            "Epoch 7/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 13843098.0000 - val_loss: 63368384.0000\n",
            "Epoch 8/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 95092912.0000 - val_loss: 115599520.0000\n",
            "Epoch 9/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 93622048.0000 - val_loss: 46352128.0000\n",
            "Epoch 10/110\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 22637684.0000 - val_loss: 387892.4688\n",
            "Epoch 11/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3153803.0000 - val_loss: 12577858.0000\n",
            "Epoch 12/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 16027320.0000 - val_loss: 15684167.0000\n",
            "Epoch 13/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 10761798.0000 - val_loss: 2991621.7500\n",
            "Epoch 14/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1023880.3750 - val_loss: 562450.0625\n",
            "Epoch 15/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1756225.8750 - val_loss: 3086465.5000\n",
            "Epoch 16/110\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 2662548.5000 - val_loss: 1341132.8750\n",
            "Epoch 17/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 604349.8750 - val_loss: 753.4976\n",
            "Epoch 18/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 177735.9688 - val_loss: 526388.8750\n",
            "Epoch 19/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 542312.6875 - val_loss: 363540.3438\n",
            "Epoch 20/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 186363.3906 - val_loss: 4213.5894\n",
            "Epoch 21/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 25145.8242 - val_loss: 96509.9766\n",
            "Epoch 22/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 109837.2266 - val_loss: 82161.5547\n",
            "Epoch 23/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 43309.0352 - val_loss: 1310.0690\n",
            "Epoch 24/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5377.9902 - val_loss: 20986.5156\n",
            "Epoch 25/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 23607.0527 - val_loss: 16751.8398\n",
            "Epoch 26/110\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 8313.7998 - val_loss: 49.4637\n",
            "Epoch 27/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1595.3228 - val_loss: 5275.7681\n",
            "Epoch 28/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5273.3652 - val_loss: 2978.3811\n",
            "Epoch 29/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1273.7996 - val_loss: 43.1370\n",
            "Epoch 30/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 603.3990 - val_loss: 1371.9818\n",
            "Epoch 31/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 1128.3871 - val_loss: 401.8054\n",
            "Epoch 32/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 138.1430 - val_loss: 90.3584\n",
            "Epoch 33/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 232.9184 - val_loss: 317.5172\n",
            "Epoch 34/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 203.6438 - val_loss: 25.3221\n",
            "Epoch 35/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 15.6423 - val_loss: 59.3922\n",
            "Epoch 36/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 74.8318 - val_loss: 55.3482\n",
            "Epoch 37/110\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 25.2573 - val_loss: 0.1958\n",
            "Epoch 38/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 8.8864 - val_loss: 21.6423\n",
            "Epoch 39/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 17.5134 - val_loss: 4.9494\n",
            "Epoch 40/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 1.7066 - val_loss: 2.7524\n",
            "Epoch 41/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.7836 - val_loss: 4.9420\n",
            "Epoch 42/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.5168 - val_loss: 0.0366\n",
            "Epoch 43/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5800 - val_loss: 1.5954\n",
            "Epoch 44/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.3773 - val_loss: 0.4297\n",
            "Epoch 45/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1710 - val_loss: 0.2538\n",
            "Epoch 46/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4002 - val_loss: 0.4225\n",
            "Epoch 47/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1977 - val_loss: 0.0307\n",
            "Epoch 48/110\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0965 - val_loss: 0.1252\n",
            "Epoch 49/110\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1217 - val_loss: 0.0483\n",
            "Epoch 50/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0406 - val_loss: 0.0417\n",
            "Epoch 51/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0467 - val_loss: 0.0500\n",
            "Epoch 52/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0463 - val_loss: 0.0379\n",
            "Epoch 53/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0347 - val_loss: 0.0279\n",
            "Epoch 54/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0325 - val_loss: 0.0277\n",
            "Epoch 55/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0330 - val_loss: 0.0276\n",
            "Epoch 56/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0329 - val_loss: 0.0275\n",
            "Epoch 57/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0322 - val_loss: 0.0273\n",
            "Epoch 58/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.0279\n",
            "Epoch 59/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0314 - val_loss: 0.0278\n",
            "Epoch 60/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 61/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0315 - val_loss: 0.0279\n",
            "Epoch 62/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0279\n",
            "Epoch 63/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0280\n",
            "Epoch 64/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0279\n",
            "Epoch 65/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0314 - val_loss: 0.0279\n",
            "Epoch 66/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 67/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 68/110\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 69/110\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0317 - val_loss: 0.0279\n",
            "Epoch 70/110\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 71/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0316 - val_loss: 0.0277\n",
            "Epoch 72/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0275\n",
            "Epoch 73/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0316 - val_loss: 0.0276\n",
            "Epoch 74/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0277\n",
            "Epoch 75/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0317 - val_loss: 0.0278\n",
            "Epoch 76/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 77/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 78/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 79/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 80/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 81/110\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 82/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 83/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 84/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0279\n",
            "Epoch 85/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0317 - val_loss: 0.0279\n",
            "Epoch 86/110\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0316 - val_loss: 0.0279\n",
            "Epoch 87/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0279\n",
            "Epoch 88/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 89/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 90/110\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0315 - val_loss: 0.0277\n",
            "Epoch 91/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 92/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.0278\n",
            "Epoch 93/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 94/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0317 - val_loss: 0.0278\n",
            "Epoch 95/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0316 - val_loss: 0.0279\n",
            "Epoch 96/110\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0315 - val_loss: 0.0279\n",
            "Epoch 97/110\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0316 - val_loss: 0.0279\n",
            "Epoch 98/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0316 - val_loss: 0.0279\n",
            "Epoch 99/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0315 - val_loss: 0.0279\n",
            "Epoch 100/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 101/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 102/110\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0314 - val_loss: 0.0278\n",
            "Epoch 103/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "Epoch 104/110\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0315 - val_loss: 0.0277\n",
            "Epoch 105/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0316 - val_loss: 0.0277\n",
            "Epoch 106/110\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0315 - val_loss: 0.0277\n",
            "Epoch 107/110\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0316 - val_loss: 0.0277\n",
            "Epoch 108/110\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0316 - val_loss: 0.0276\n",
            "Epoch 109/110\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0316 - val_loss: 0.0278\n",
            "Epoch 110/110\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0315 - val_loss: 0.0278\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['carbon_emission_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import joblib\n",
        "\n",
        "# Step 1: Read the CSV file\n",
        "df = pd.read_csv('output.csv')\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'], dayfirst=True).map(pd.Timestamp.toordinal)\n",
        "# Normalize the total carbon emission amounts\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['total_carbon_emission'] = scaler.fit_transform(df[['total_carbon_emission']])\n",
        "\n",
        "# Step 3: Split the data\n",
        "X = df['date'].values.reshape(-1, 1)\n",
        "y = df['total_carbon_emission'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Create the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(1,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Step 5: Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Step 6: Train the model\n",
        "model.fit(X_train, y_train, epochs=110, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "model.evaluate(X_test, y_test)\n",
        "\n",
        "joblib.dump(model, 'carbon_emission_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Load the model and the pre-fitted scaler\n",
        "model = joblib.load('carbon_emission_model.pkl')\n",
        "#scaler = joblib.load('scaler.pkl')  # Load the pre-fitted scaler\n",
        "\n",
        "# Get user input\n",
        "month_year_str = input(\"Enter month and year (YYYY-MM): \")\n",
        "year, month = map(int, month_year_str.split('-'))\n",
        "\n",
        "# Generate all Wednesdays of the specified month\n",
        "first_day = datetime(year, month, 1)\n",
        "last_day = (first_day.replace(month=month % 12 + 1, day=1) - timedelta(days=1)).day\n",
        "days = [first_day + timedelta(days=i) for i in range(last_day)]\n",
        "\n",
        "# Prepare the data for prediction\n",
        "day_ordinals = np.array([datetime.toordinal(day) for day in days]).reshape(-1, 1)\n",
        "predicted_emissions = model.predict(day_ordinals)\n",
        "predicted_emissions = scaler.inverse_transform(predicted_emissions)\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results = pd.DataFrame({\n",
        "    'Date': [day.strftime(\"%Y-%m-%d\") for day in days],\n",
        "    'Predicted Carbon Emission': predicted_emissions.flatten()\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "csv_filename = f\"predicted_emissions_{year}_{month:02d}.csv\"\n",
        "results.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"Predicted carbon emissions saved to {csv_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwuJJXgse3FC",
        "outputId": "2a504be8-1054-42b8-f1e6-c8424a204bdc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter month and year (YYYY-MM): 2024-10\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Predicted carbon emissions saved to predicted_emissions_2024_10.csv\n"
          ]
        }
      ]
    }
  ]
}